{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbedding\n",
    "from langchain_groq import chatGroq\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd62c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357b29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os. getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6933863",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os. environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os. environ[\"LANGCHAIN_API_KEY\"]= LANGCHAIN_API_KEY\n",
    "os. environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os. environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith. langchain.com\"\n",
    "os. environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a70f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "llm = ChatGroq(model_name='Gemma2-9b-It')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa3f39",
   "metadata": {},
   "source": [
    "### Simple AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4bae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    question = input(\"Type your question. if you want to quit the chat , write quit\")\n",
    "    if question.lower() != \"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "\n",
    "    else:\n",
    "        print(\"Good bye till next time\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ed2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88894a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7718631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory = RunnableWithMessageHistory(llm, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fff5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory.invoke((\"Hi, I'm Hamid\"), config=config).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24924559",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory.invoke((\"tell me what is my name\"), config=config).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703f42b",
   "metadata": {},
   "source": [
    "### RAG with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading txt files from source directroy\n",
    "loader = DirectoryLoader(\"../data\", glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Chunks using RecursiveCharactertextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846db8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BGE Embddings\n",
    "\n",
    "'''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs ='normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "model_name=model_name,\n",
    "model_kwargs=model_kwargs,\n",
    "encode_kwargs=encode_kwargs,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating retriever using vector db\n",
    "db = Chroma.from_documents(new_docs, embedding=embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"What is llama3? can you highlight 3 important points?\"\n",
    "print(retrieval_chain.invoke(question_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee461e",
   "metadata": {},
   "source": [
    "### Start with Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fb85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun, YouTubeSearchTool\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wikipedia youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ea8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper()\n",
    "\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682729e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.name, tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cf118",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7650125",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_2 = YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff208709",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_2.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_2.run(\"freecodecamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bdd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_3 = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185865e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_3.invoke({\"query\": \"What happend in the latest burning man floods?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, load_tools, initialize_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5118d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_4 = load_tools([\"wikipedia\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tool_4, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cee697",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"What is current GDP of USA?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
