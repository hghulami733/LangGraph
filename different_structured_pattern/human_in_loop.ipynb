{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b2bc52",
   "metadata": {},
   "source": [
    "For some actions , we may need to require human approval before running to ensure that everythin is running as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "import operator, json\n",
    "from typing import TypedDict, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(first_number: int, secont_number: int) -> int:\n",
    "    \"\"\" Multyply two interger numbers \"\"\"\n",
    "    return first_number * secont_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply({\"first_number\": 20, \"second_number\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply.invoke({\"first_number\": 20, \"second_number\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expencive tool\n",
    "@tool\n",
    "def web_search(query:str):\n",
    "    \"\"\" Perform the web search on the user query \"\"\"\n",
    "    tavily = TavilySearchResults()\n",
    "    result = tavily.invoke(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7be39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search(\"Who is the current president of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search.invoke(\"Who is the current president of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a321f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_kit_1 = [web_search, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = llm.bind_tools(tools_kit_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {tool.name : tool for tool in tools_kit_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20430e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_with_tools.invoke(\"Who is the current president of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22db0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_details = response.additional_kwargs.get(\"tool_calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf1c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d19ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_details[0][\"function\"][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f79dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_details[0][\"function\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping[tool_details[0][\"function\"][\"name\"]].invoke(json.loads(tool_details[0][\"function\"][\"arguments\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006884c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[-1] # Fetching the user question\n",
    "    return {\"messages\": [model_with_tools.invoke(question)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44643bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_tool(state:AgentState):\n",
    "    tool_details = state[\"messages\"][-1].additional_kwargs.get(\"tool_calls\", [])[0]\n",
    "\n",
    "    if tool_details is None:\n",
    "        raise Exception(\"no tool call found\")\n",
    "    \n",
    "    print(f\"Selected tool: {tool_details.get(\"function\").get(\"name\")}\")\n",
    "\n",
    "    if tool_details.get(\"function\").get(\"name\") == \"search\":\n",
    "        response = input(prompt=f\"[y/n] continue with expensive web search?\")\n",
    "        if response == \"n\":\n",
    "            raise Exception(\"web search was discarded\")\n",
    "\n",
    "    response = tool_mapping[tool_details[\"function\"][\"name\"]].invoke(json.loads(tool_details.get(\"function\")))\n",
    "    return {\"messages\": [response]}  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    tool_calls = state[\"messages\"][-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "\n",
    "    if len(tool_calls):\n",
    "        return \"tool\"\n",
    "    \n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ba9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "graph = StateGraph(AgentState) # StateGraph with AgentState\n",
    "\n",
    "graph.add_node(\"ai_assitant\", invoke_model)\n",
    "graph.add_node(\"tool\", invoke_tool)\n",
    "\n",
    "graph.add_conditional_edges(\"ai_assistant\", router, {\"tool\":\"tool\", \"end\":END})\n",
    "\n",
    "graph.add_edge(\"tool\", END)\n",
    "\n",
    "#graph.add_edge(\"tool\", \"ai_assistant\")\n",
    "\n",
    "graph.set_entry_point(\"ai_assistant\")\n",
    "\n",
    "app_1 = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7072e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app_1.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be asked before searching the web\n",
    "for s in app_1.stream({\"messages\": [\"Who is the current president of USA?\"]}):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe89d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will not be asked before doing the multiplication\n",
    "for s in app_1.stream({\"messages\": [\"what is the result of multiplication of 15 and 62?\"]}):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d54f8",
   "metadata": {},
   "source": [
    "LangGraph supports human-in-loop workflows in a number of ways, in this section, i will use LangGraph's interrupt_before functionality to always break the tool node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf090f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState1(TypedDict):\n",
    "    messages : Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa823623",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0910c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94077ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_assistant(state: AgentState1):\n",
    "    return {\"messages\": [llm_with_tool.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c65e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(AgentState1)\n",
    "\n",
    "graph_builder.add_node(\"ai_assistant\", ai_assistant)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"ai_assistant\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"ai_assistant\",\n",
    "    tools_condition\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"at_assistant\")\n",
    "\n",
    "app_2 = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "\n",
    "    # This is new\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note : can also interrupt_after_ tools, if desires.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app_2.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5641733",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What is the capital of USA?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confing is the **second positional argument** to stream() or invoke()\n",
    "\n",
    "events = app_2.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992aad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for envet in events:\n",
    "    if \"messages\" in envet:\n",
    "        envet[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379db698",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = app_2.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message = snapshot.values[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'None' will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = app_2.stream(None, config=config, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for envet in events:\n",
    "    if \"messages\" in envet:\n",
    "        envet[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What is the weather there?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app_2.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for envet in events:\n",
    "    if \"messages\" in envet:\n",
    "        envet[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_1 = app_2.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_1.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message_1 = snapshot_1.values[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_message_1.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'None' will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = app_2.stream(None, config=config, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a15d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for envet in events:\n",
    "    if \"messages\" in envet:\n",
    "        envet[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_2 = app_2.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dec273",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_2.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cdf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"give me the recent news of it?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app_2.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eafdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for envet in events:\n",
    "    if \"messages\" in envet:\n",
    "        envet[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_3 = app_2.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604026b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_message = snapshot_3.values[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_id = current_message.tool_calls[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8510873",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"it is just related to raining which is happening on daily basis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95526409",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_messages = [\n",
    "    ToolMessage(content=answer, tool_call_id=tool_call_id),\n",
    "    AIMessage(content=answer),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902835f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_2.update_state(\n",
    "    config=config,\n",
    "    {\"messages\": new_messages},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app_2.get_state(config=config).values[\"messages\"][-1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
