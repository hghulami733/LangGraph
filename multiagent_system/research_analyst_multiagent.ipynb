{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.messages import convert_to_messages\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e727a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search.invoke(\"What is the GDP of USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"]\n",
    "):\n",
    "    \"\"\" Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with 'print(...)'. This is visible to the User. \"\"\"\n",
    "\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repl(e)}\"\n",
    "    \n",
    "    result_str = f\"Successfully executed: \\n'\\'\\'python\\n{code}\\n'\\'\\'\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcd505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(instruction: str) -> str:\n",
    "    return (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{instruction}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_node(last_message: BaseMessage, goto:str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return END\n",
    "    return goto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_system_prompt(\n",
    "    \"You can only do research. You are working with a chart generator colleague.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7adb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = create_react_agent(\n",
    "    openai_model,\n",
    "    tools=[web_search],\n",
    "    prompt=make_system_prompt(\n",
    "        \"You can only do research. You are working with a chart generator colleague.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_agent = create_react_agent(\n",
    "    openai_model,\n",
    "    tools=[python_repl_tool],\n",
    "    prompt=make_system_prompt(\n",
    "        \"You can only generate charts. You are working with a researcher colleague.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95565b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state:MessagesState) -> Command[Literal[\"chart_generator\", END]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": result[\"messages\"]\n",
    "        },\n",
    "        goto=goto\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f206b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_node(state: MessagesState) -> Command[Literal[\"researcher\", END]]:\n",
    "    result = chart_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            # Share internal message history of chart agant with other agents\n",
    "            \"messages\": result[\"messages\"]\n",
    "        },\n",
    "        goto=goto\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86063f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = {\"messages\", [(\"user\", \"get the USA's GDP over the past 3 years. then make a line chart of it. Once you make the chart, Finish.\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(input_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
