{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Annotated\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.messages import convert_to_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6358a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a728c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e58091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(state):\n",
    "    results = state[\"num1\"] + state[\"num2\"]\n",
    "    print(f\"addition result: {results}\")\n",
    "    return Command(goto=\"multiply\", update={\"sum\": results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829602b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"num1\": 1, \"num2\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5a8674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition result: 3\n",
      "Command(update={'sum': 3}, goto='multiply')\n"
     ]
    }
   ],
   "source": [
    "print(add_numbers(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47fde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\" Ask multiplication agent for help \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f47778",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_additional_expert():\n",
    "    \"\"\" Ask addition agent for help \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e42db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tool = openai_model.bind_tools([transfer_to_multiplication_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd51d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = model_with_tool.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe570fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = model_with_tool.invoke(\"What's (3 + 9) * 54. provide me the output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74372d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_expert(state:MessagesState) -> Command[Literal[\"multiplication_expert\", \"__end__\"]]:\n",
    "    system_prompt = (\n",
    "        \"You are an addition expert. you can ask the multiplication expert for help with multiplication.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt()}] + state[\"messages\"]\n",
    "    ai_msg = openai_model.bind_tools([transfer_to_multiplication_expert]).invoke(messages)\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id\n",
    "        }\n",
    "\n",
    "        return Command(\n",
    "            goto=\"multiplitcational_expert\", update={\"messages\": [ai_msg, tool_msg]}\n",
    "        )\n",
    "    \n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9bf7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_expert(state:MessagesState) -> Command[Literal[\"additional_expert\", \"__end__\"]]:\n",
    "    system_prompt = (\n",
    "        \"You are an multiplication expert. you can ask the addition expert for help with addition.\"\n",
    "        \"Always do your portion of calculation before the handoff.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    ai_msg = openai_model.bind_tools([transfer_to_additional_expert]).invoke(messages)\n",
    "\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id\n",
    "        }\n",
    "\n",
    "        return Command(goto=\"additional_expert\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "    \n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"additional_expert\", additional_expert)\n",
    "workflow.add_node(\"multiplication_expert\", multiplication_expert)\n",
    "\n",
    "workflow.add_edge(START, \"additional_expert\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b279970",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"messages\": \"What's (3 + 3) * 53. provide me the output\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_messages(updata):\n",
    "    if isinstance(updata, tuple):\n",
    "        ns, updata = updata\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "        \n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    for node_name, node_update in updata.items():\n",
    "        print(f\"Update from node {node_name}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        for m in convert_to_messages(node_update[\"messages\"]):\n",
    "            m.pretty_print()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the graph with an expression that requires both additional and multiplication:\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"user\", \"What's (3 + 6) * 53. provide me the output\")]}\n",
    "):\n",
    "    print(\"**** Chunk....****\")\n",
    "\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2af517",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_travel_advisor():\n",
    "    \"\"\" Ask travel advisor for help. \"\"\"\n",
    "    return\n",
    "\n",
    "@tool\n",
    "def transfer_to_hotel_advisor():\n",
    "    \"\"\" Ask hotel advisor for help. \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_advisor(state: MessagesState) -> Command[Literal[\"hotel_advisor\", \"__end__\"]]:\n",
    "    system_prompr = (\n",
    "        \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc).\"\n",
    "        \"If you need hotel recommendations, ask 'hotel_advisor' for help.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompr}] + state[\"messages\"]\n",
    "\n",
    "    ai_msg = openai_model.bind_tools([transfer_to_hotel_advisor]).invoke(messages)\n",
    "\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id\n",
    "        }\n",
    "\n",
    "        return Command(goto=\"hotel_advisor\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "    \n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotel_advisor(state: MessagesState) -> Command[Literal[\"travel_advisor\", \"__end__\"]]:\n",
    "    system_prompr = (\n",
    "        \"You are a hotel expert that can provide hotel recommendations for a given distination.\"\n",
    "        \"If you need help picking travel destinations, ask 'travel_advisor' for help.\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompr}] + state[\"messages\"]\n",
    "\n",
    "    ai_msg = openai_model.bind_tools([transfer_to_travel_advisor]).invoke(messages)\n",
    "\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id\n",
    "        }\n",
    "\n",
    "        return Command(goto=\"travel_advisor\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "    \n",
    "    return {\"messages\": [ai_msg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_1 = StateGraph(MessagesState)\n",
    "\n",
    "workflow_1.add_node(\"travel_advisor\", travel_advisor)\n",
    "workflow_1.add_node(\"hotel_advisor\", hotel_advisor)\n",
    "\n",
    "workflow_1.add_edge(START, \"travel_advisor\")\n",
    "\n",
    "app_1 = workflow_1.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app_1.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54656d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = ({\"messages\": [(\"user\", \"I am planning a trip to California in the USA from Tehran. What are the best flight routes and Can you guide me on suggesting the best hotel?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d74d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1.invoke(input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58656490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in app_1.stream(\n",
    "    input_1\n",
    "):\n",
    "    print(\"**** Chunk....****\")\n",
    "\n",
    "    pretty_print_messages(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
