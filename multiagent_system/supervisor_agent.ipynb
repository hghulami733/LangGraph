{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d144ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState, END, START, StateGraph\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603837d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\", api_key=\"api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ffad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_model.invoke(\"Hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    clean_text = re.sub(r\"<think>.*?</think>\\s*\", \"\", text, flags=re.DOTALL)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = groq_model.invoke(\"hi\")\n",
    "clean_text(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search.invoke(\"What is GDP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "x = 5\n",
    "y = x * 2\n",
    "print(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edaeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repl.run(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def python_repl_text(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\" Use this to execute python code and do math. If you want to see the output of a value.\n",
    "    you should print it out with 'print(...)'. This is visible to the user.\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {e}\"\n",
    "    \n",
    "    return f\"Successfully executed: {code} Stdout: {result}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(python_repl_text.invoke(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96870ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"researcher\", \"coder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa72805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = members+[\"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Routor(TypedDict):\n",
    "    \"\"\" Worker to route to next. if no workers needed, route to FINISH.\"\"\"\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    next : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are a supervisor, tasked with managing a conversation between the following workers: {members}.\n",
    "Given the following user request, respond with the worker to act next.\n",
    "Each worker will perform a task and respond with their results and status.\n",
    "When finished, respond with FINISH.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\"role\": \"system\", \"content\": system_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"next\": [\"hi\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95598686",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\"role\": \"system\", \"content\": system_prompt},] + state[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4dc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: State) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},] + state[\"messages\"]\n",
    "    response = groq_model.with_structured_output(Routor).invoke(messages)\n",
    "    goto = response(\"next\")\n",
    "    print(\"below is my goto***************************\")\n",
    "    print(goto)\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"role\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39eb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    research_agent = create_react_agent(groq_model, tools=[tavily_search], prompt=\"You are a researcher. DO NOT do any math.\")\n",
    "    result = research_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state:State) -> Command[Literal[\"supervisor\"]]:\n",
    "    code_agent = create_react_agent(groq_model, tools=[python_repl_text])\n",
    "    result = code_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49320f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "graph = StateGraph(StateGraph)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"researcher\", research_node)\n",
    "graph.add_node(\"codeer\", code_node)\n",
    "\n",
    "graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf26dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fadafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the graph created , we can now invoke it and see how it performs:\n",
    "for s in app.stream({\"messages\": [(\"user\", \"What's the square root of 72?\")]}, subgraphs=True):\n",
    "    print(s)\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16939c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"What's the square root of 72?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"What's the afficient python code to get prime nubmers?\")]}, subgraphs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
