{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1956a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee446cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "llm = ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3759b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb85d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a696e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b39de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "\n",
    "doc_splite = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splite,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"retrieve_blog_posts\",\n",
    "    description=\"Search and return information about Lilian Weng blog posts on LLM agents , prompt engineering, and adversarial attacks on LLMs.\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a162d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\" Binary score for relevance check on retrieved documents. \"\"\"\n",
    "    binary_score : str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\" You are a grader checking if a document is relevant to a user's question. The check has to be done very strictly..\n",
    "If the document has words or meanings related to the question, mark it as relevant.\n",
    "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\n",
    "\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3975fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9986fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is Hamid?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23951e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93634b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is ai agent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33199110",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f34d09",
   "metadata": {},
   "source": [
    "### Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2036d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\" Binary score for hallucination present in generation answer. \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd257a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader_1 = llm.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17653b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt \n",
    "system_1 = \"\"\"\n",
    "You are a grader checking if an LLM generation is grounded in or sopported by a set of retrieved facts.\n",
    "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts.\n",
    "\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_1),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3404c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_grader = hallucination_prompt | structured_llm_grader_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hallucination_grader.invoke({\"documents\": docs, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Grader\n",
    "# data model\n",
    "class GraderAnswer(BaseModel):\n",
    "    \"\"\" Binary score to assess answer addresses question. \"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader_2 = llm.with_structured_output(GraderAnswer)\n",
    "\n",
    "# prompt \n",
    "system_2 = \"\"\"\n",
    "You are a grader assessing whether an answer addresses / resolves a question \\n\n",
    "Give a binary score 'yes' or 'no' . Yes' means that the answer resolves the question.\n",
    "\"\"\"\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_2)\n",
    "        (\"human\", \"User question \\n\\n {question} \\n\\n LLM generation: {generation}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer_grader.invoke({\"question\": question, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b22ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.\n",
    "    You are given both a question and a document.\n",
    "    - First, check if the question is relevant to the document by identifying a connection or relevance between them.\n",
    "    - If there is a little relevancy, rewrite the question based on the semantic intent of the question and the context of the document.\n",
    "    - If no relevance is found, simply return \"question not relevant.\"\n",
    "    Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "\n",
    "        [(\"system\", system),\n",
    "\n",
    "        (\n",
    "            \"human\", \"\"\"Here is the initial question: \\n\\n (question} \\n,\n",
    "            Here is the document: \\n\\n {documents} \\n ,\n",
    "            Formulate an improved question. if possible other return 'question not relevant'.\"\"\"\n",
    "        )]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d1e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is the current president of USA?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7691dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_rewriter.invoke({\"question\": question, \"documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState():\n",
    "    question : str\n",
    "    generation : str\n",
    "    documents : List[str]\n",
    "    filter_documents: List[str]\n",
    "    unfilter_documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:AgentState):\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state: AgentState):\n",
    "    print(\"--- CHECK DOCUMENTS RELEVANCE TO THE QUESTION ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    unfiltered_docs = []\n",
    "\n",
    "    for doc in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": doc})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        if grade == \"yes\":\n",
    "            print(\"--- GRADE: DOCUMENT RELEVANT ---\")\n",
    "            filtered_docs.append(doc)\n",
    "\n",
    "        else:\n",
    "            print(\"--- GRADE: DOCUMENT NOT RELEVANT ---\")\n",
    "            unfiltered_docs.append(doc)\n",
    "\n",
    "    if len(unfiltered_docs) > 1:\n",
    "        return {\"unfilter_documents\": unfiltered_docs, \"filter_documents\":[], \"question\": question}\n",
    "    \n",
    "    else:\n",
    "        return {\"filter_documents\": filtered_docs, \"unfilter_documents\": [], \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b906c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state:AgentState):\n",
    "    print(\"--- ACCESS GRADED DOCUMENTS ---\")\n",
    "    ulfiltered_documents = state[\"unfilter_documents\"]\n",
    "    filtered_documents = state[\"filter_documents\"]\n",
    "\n",
    "    if ulfiltered_documents:\n",
    "        print(\"--- ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY ---\")\n",
    "        return \"transform_query\"\n",
    "    \n",
    "    if filtered_documents:\n",
    "        print(\"--- DECISION: GENERATE ---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8403f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState):\n",
    "    print(\"--- GENERATE ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\"content\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ddc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state:AgentState):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    print(f\"this is my document: {documents}\")\n",
    "    response = question_rewriter.invoke({\"question\": question, \"documents\": documents})\n",
    "    print(f\"--- RESPONSE --- {response}\")\n",
    "\n",
    "    if response == \"question not relevant\":\n",
    "        print(\"--- QUESTION IS NOT AT ALL RELEVANT ---\")\n",
    "        return {\"documents\": documents, \"question\": response, \"generation\": \"question was not at all relevant\"}\n",
    "    \n",
    "    else:\n",
    "        return {\"documents\": documents, \"question\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate_after_transformation(state:AgentState):\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    if question == \"question not relevant\":\n",
    "        return \"query_not_at_all_relevant\"\n",
    "    \n",
    "    else:\n",
    "        return \"Retriever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dadbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_vs_documents_and_question(state:AgentState):\n",
    "    print(\"--- CHECK HELLUCINATIONS ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Check hallucinations\n",
    "    if grade == \"yes\":\n",
    "        print(\"--- DECISION: GENERATION IS GROUNDED IN DOCUMENTS ---\")\n",
    "\n",
    "        print(\"--- GRADE GENERATION VS QUESTION ---\")\n",
    "\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "\n",
    "        grade = score.binary_score\n",
    "\n",
    "        if grade == \"no\":\n",
    "            print(\"--- DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
    "            return \"useful\"\n",
    "        \n",
    "        else:\n",
    "            print(\"--- DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "            return \"not useful\"\n",
    "        \n",
    "    else:\n",
    "        pprint(\"--- DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45627c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
    "workflow.add_node(\"Grading_Generated_Documents\", grade_documents)\n",
    "workflow.add_node(\"Content_Generator\", generate)\n",
    "workflow.add_node(\"Transform_User_Query\", transform_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(START, \"Docs_Vector_Retrieve\")\n",
    "workflow.add_edge(\"Docs_Vector_Retrieve\", \"Grading_Generated_Documents\")\n",
    "workflow.add_conditional_edges(\"Docs_Vector_Retrieve\",\n",
    "                               decide_to_generate,\n",
    "                                {\n",
    "                                    \"generate\": \"Content_Generator\",\n",
    "                                    \"transform_query\": \"Transform_Query\"\n",
    "                                })\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Content_Generator\",\n",
    "    grade_generation_vs_documents_and_question,\n",
    "    {\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"Transform_User_Query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Transform_User_Query\",\n",
    "    decide_to_generate_after_transformation,\n",
    "    {\n",
    "        \"Retriever\": \"Docs_Vectore_Retrieve\",\n",
    "        \"query_not_at_all_relevant\": END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c21a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Explain how the different types of agent memory work\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(input=inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Who is a prompt engineering?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d97469",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(input=inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9c2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Who is the first president of USA?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(input=inputs)[\"generation\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
